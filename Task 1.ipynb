{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bf6bd0-3dd2-4711-9cce-b6dbb463e05d",
   "metadata": {},
   "source": [
    "# Task 1: Understand body language by gesture recognition with fully connected neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebc998-13f5-4195-a67b-df152735d5b9",
   "metadata": {},
   "source": [
    "## 1. Do literature search on gesture recognition and its application in Human-Robot Interaction. Summarize what you have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d7314-8adc-4e9e-878f-1cf6b6d98a2d",
   "metadata": {},
   "source": [
    "## 2. Referring to the previous example about building a neural network based classifier, use what you have learned to read the code for gesture classification below and design your own network architecture using fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7337f2e1-9947-4985-a97b-c807c311e28f",
   "metadata": {},
   "source": [
    "## 3. Run the model. Analyse and comment on the performance of your model based on fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "188f9266-fc0b-4001-84ba-73e7804606e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import torch.utils.data as utils_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0830f-0431-4d27-aed5-5fa3156d6091",
   "metadata": {},
   "source": [
    "## 1) data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926df832-9898-4e91-8beb-d0790da1bf0c",
   "metadata": {},
   "source": [
    "Define a function to preprocess the images including resizing and binaryzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1d99d8-da0f-4305-8fbd-1e346abc560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSkinImage(filePath, resize_HW=48):\n",
    "    # step 1\n",
    "    # read the image\n",
    "    original = cv2.imread(filename=filePath)\n",
    "\n",
    "    # step 2\n",
    "    # resize the image to\n",
    "    image_resized = cv2.resize(original, (resize_HW, resize_HW))\n",
    "\n",
    "    # step 3\n",
    "    # convert the image from rgb to YCbCr\n",
    "    image_ycbcr = cv2.cvtColor(image_resized, cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    # step 4\n",
    "    # get the central color of the image\n",
    "    # expected the hand to be in the central of the image\n",
    "    Cb_center_color = image_ycbcr[int(resize_HW/2), int(resize_HW/2), 1]\n",
    "    Cr_center_color = image_ycbcr[int(resize_HW/2), int(resize_HW/2), 2]\n",
    "    # set the range\n",
    "    Cb_Difference = 15\n",
    "    Cr_Difference = 10\n",
    "\n",
    "    # step 5\n",
    "    # detect skin pixels\n",
    "    Cb = image_ycbcr[:, :, 1]\n",
    "    Cr = image_ycbcr[:, :, 2]\n",
    "    index = np.where((Cb >= Cb_center_color-Cb_Difference) & (Cb <= Cb_center_color+Cb_Difference)\n",
    "                     & (Cr >= Cr_center_color-Cr_Difference) & (Cr <= Cr_center_color+Cr_Difference))\n",
    "\n",
    "    # Mark detected pixels and output\n",
    "    image_output = np.zeros((resize_HW, resize_HW))\n",
    "    image_output[index] = 255\n",
    "\n",
    "    # show image\n",
    "    # cv2.imshow(\"\", image_output)\n",
    "    # cv2.waitKey(0)\n",
    "    return image_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf454b1-4248-4a3e-9bf8-9304d64131c4",
   "metadata": {},
   "source": [
    "Deal with all the images using the function defined above.\n",
    "The processed data is stored in a new folder 'dataset_processed'.\n",
    "\n",
    "Generate labels for each class. (class 0, 1, ..., num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67e88cb-3dc7-4bfe-935f-5cba75a782d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/images\\left\\left (1).jpg\n",
      "./dataset/images\\left\\left (10).jpg\n",
      "./dataset/images\\left\\left (11).jpg\n",
      "./dataset/images\\left\\left (12).jpg\n",
      "./dataset/images\\left\\left (13).jpg\n",
      "./dataset/images\\left\\left (14).jpg\n",
      "./dataset/images\\left\\left (15).jpg\n",
      "./dataset/images\\left\\left (16).jpg\n",
      "./dataset/images\\left\\left (17).jpg\n",
      "./dataset/images\\left\\left (18).jpg\n",
      "./dataset/images\\left\\left (19).jpg\n",
      "./dataset/images\\left\\left (2).jpg\n",
      "./dataset/images\\left\\left (20).jpg\n",
      "./dataset/images\\left\\left (21).jpg\n",
      "./dataset/images\\left\\left (22).jpg\n",
      "./dataset/images\\left\\left (23).jpg\n",
      "./dataset/images\\left\\left (24).jpg\n",
      "./dataset/images\\left\\left (25).jpg\n",
      "./dataset/images\\left\\left (26).jpg\n",
      "./dataset/images\\left\\left (27).jpg\n",
      "./dataset/images\\left\\left (3).jpg\n",
      "./dataset/images\\left\\left (4).jpg\n",
      "./dataset/images\\left\\left (5).jpg\n",
      "./dataset/images\\left\\left (6).jpg\n",
      "./dataset/images\\left\\left (7).jpg\n",
      "./dataset/images\\left\\left (8).jpg\n",
      "./dataset/images\\left\\left (9).jpg\n",
      "./dataset/images\\palm\\palm (1).jpg\n",
      "./dataset/images\\palm\\palm (10).jpg\n",
      "./dataset/images\\palm\\palm (11).jpg\n",
      "./dataset/images\\palm\\palm (12).jpg\n",
      "./dataset/images\\palm\\palm (13).jpg\n",
      "./dataset/images\\palm\\palm (2).jpg\n",
      "./dataset/images\\palm\\palm (3).jpg\n",
      "./dataset/images\\palm\\palm (4).jpg\n",
      "./dataset/images\\palm\\palm (5).jpg\n",
      "./dataset/images\\palm\\palm (6).jpg\n",
      "./dataset/images\\palm\\palm (7).jpg\n",
      "./dataset/images\\palm\\palm (8).jpg\n",
      "./dataset/images\\palm\\palm (9).jpg\n",
      "./dataset/images\\peace\\peace (1).jpg\n",
      "./dataset/images\\peace\\peace (10).jpg\n",
      "./dataset/images\\peace\\peace (11).jpg\n",
      "./dataset/images\\peace\\peace (12).jpg\n",
      "./dataset/images\\peace\\peace (13).jpg\n",
      "./dataset/images\\peace\\peace (14).jpg\n",
      "./dataset/images\\peace\\peace (2).jpg\n",
      "./dataset/images\\peace\\peace (3).jpg\n",
      "./dataset/images\\peace\\peace (4).jpg\n",
      "./dataset/images\\peace\\peace (5).jpg\n",
      "./dataset/images\\peace\\peace (6).jpg\n",
      "./dataset/images\\peace\\peace (7).jpg\n",
      "./dataset/images\\peace\\peace (8).jpg\n",
      "./dataset/images\\peace\\peace (9).jpg\n",
      "./dataset/images\\right\\right (1).jpg\n",
      "./dataset/images\\right\\right (10).jpg\n",
      "./dataset/images\\right\\right (11).jpg\n",
      "./dataset/images\\right\\right (12).jpg\n",
      "./dataset/images\\right\\right (13).jpg\n",
      "./dataset/images\\right\\right (14).jpg\n",
      "./dataset/images\\right\\right (15).jpg\n",
      "./dataset/images\\right\\right (16).jpg\n",
      "./dataset/images\\right\\right (17).jpg\n",
      "./dataset/images\\right\\right (18).jpg\n",
      "./dataset/images\\right\\right (19).jpg\n",
      "./dataset/images\\right\\right (2).jpg\n",
      "./dataset/images\\right\\right (20).jpg\n",
      "./dataset/images\\right\\right (21).jpg\n",
      "./dataset/images\\right\\right (22).jpg\n",
      "./dataset/images\\right\\right (23).jpg\n",
      "./dataset/images\\right\\right (24).jpg\n",
      "./dataset/images\\right\\right (3).jpg\n",
      "./dataset/images\\right\\right (4).jpg\n",
      "./dataset/images\\right\\right (5).jpg\n",
      "./dataset/images\\right\\right (6).jpg\n",
      "./dataset/images\\right\\right (7).jpg\n",
      "./dataset/images\\right\\right (8).jpg\n",
      "./dataset/images\\right\\right (9).jpg\n",
      "['left', 'palm', 'peace', 'right']\n",
      "['left (1).jpg', 'left (10).jpg', 'left (11).jpg', 'left (12).jpg', 'left (13).jpg', 'left (14).jpg', 'left (15).jpg', 'left (16).jpg', 'left (17).jpg', 'left (18).jpg', 'left (19).jpg', 'left (2).jpg', 'left (20).jpg', 'left (21).jpg', 'left (22).jpg', 'left (23).jpg', 'left (24).jpg', 'left (25).jpg', 'left (26).jpg', 'left (27).jpg', 'left (3).jpg', 'left (4).jpg', 'left (5).jpg', 'left (6).jpg', 'left (7).jpg', 'left (8).jpg', 'left (9).jpg']\n",
      "['palm (1).jpg', 'palm (10).jpg', 'palm (11).jpg', 'palm (12).jpg', 'palm (13).jpg', 'palm (2).jpg', 'palm (3).jpg', 'palm (4).jpg', 'palm (5).jpg', 'palm (6).jpg', 'palm (7).jpg', 'palm (8).jpg', 'palm (9).jpg']\n",
      "['peace (1).jpg', 'peace (10).jpg', 'peace (11).jpg', 'peace (12).jpg', 'peace (13).jpg', 'peace (14).jpg', 'peace (2).jpg', 'peace (3).jpg', 'peace (4).jpg', 'peace (5).jpg', 'peace (6).jpg', 'peace (7).jpg', 'peace (8).jpg', 'peace (9).jpg']\n",
      "['right (1).jpg', 'right (10).jpg', 'right (11).jpg', 'right (12).jpg', 'right (13).jpg', 'right (14).jpg', 'right (15).jpg', 'right (16).jpg', 'right (17).jpg', 'right (18).jpg', 'right (19).jpg', 'right (2).jpg', 'right (20).jpg', 'right (21).jpg', 'right (22).jpg', 'right (23).jpg', 'right (24).jpg', 'right (3).jpg', 'right (4).jpg', 'right (5).jpg', 'right (6).jpg', 'right (7).jpg', 'right (8).jpg', 'right (9).jpg']\n"
     ]
    }
   ],
   "source": [
    "path = './dataset/images'\n",
    "path_processed = './dataset_processed/images'\n",
    "\n",
    "# -------------------images processing--------------\n",
    "for mainDir, subDir, fileList in os.walk(path):\n",
    "    for file in fileList:\n",
    "        currentPath = os.path.join(mainDir, file)\n",
    "        print(currentPath)\n",
    "        processedImage = processSkinImage(currentPath)\n",
    "\n",
    "        new_mainDir = path_processed + mainDir.split(path)[-1] # mainDir.split(path)[-1] 的值为 /left  /right等\n",
    "        # new_mainDir 应该为 \"./dataset_processed/images/left\"等\n",
    "        if not os.path.exists(new_mainDir):\n",
    "            os.makedirs(new_mainDir)\n",
    "        cv2.imwrite(os.path.join(new_mainDir, file), processedImage)\n",
    "\n",
    "# -----------------label generation----------------\n",
    "label_path = './dataset_processed/labels'\n",
    "if not os.path.exists(label_path):\n",
    "    os.makedirs(label_path)\n",
    "\n",
    "files = os.listdir(path)\n",
    "print(files)\n",
    "for i, file in enumerate(files):\n",
    "    subclass_label_path = os.path.join(label_path, file+'.txt')\n",
    "    with open(subclass_label_path, 'w') as f:\n",
    "        f.write('#label\\n')\n",
    "    print(os.listdir(os.path.join(path_processed, file)))\n",
    "    for _ in range(len(os.listdir(os.path.join(path_processed, file)))):\n",
    "        with open(subclass_label_path, 'a') as f:\n",
    "            f.write('{:d}\\n'.format(i))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac1d92-e269-4297-8b52-6be08c37e503",
   "metadata": {},
   "source": [
    "## 2) load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e44415d-726c-401c-9a78-5dcd2c140ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 2304)\n",
      "(78,)\n"
     ]
    }
   ],
   "source": [
    "Image = []\n",
    "path_images = './dataset_processed/images'\n",
    "for mainDir, subDir, fileList in os.walk(path_images):\n",
    "    for file in fileList:\n",
    "        \n",
    "        currentPath = os.path.join(mainDir, file)\n",
    "        # print(currentPath)\n",
    "        Image.append(cv2.imread(currentPath)[:, :, 0])\n",
    "Image = np.array(Image)\n",
    "dataset_size, H, W = Image.shape\n",
    "# for FCNN model, the image need to be stretched into one dimension: (b, h, w)->(b, h*w)\n",
    "Image = Image.reshape(dataset_size, -1)\n",
    "print(Image.shape)\n",
    "\n",
    "Label = []\n",
    "path_labels = './dataset_processed/labels'\n",
    "for file in os.listdir(path_labels):\n",
    "    Label.append(np.loadtxt(os.path.join(path_labels, file)))\n",
    "    #print(np.loadtxt(os.path.join(path_labels, file)))\n",
    "#print(Label)\n",
    "Label = np.array(list(itertools.chain.from_iterable(Label)))#去掉一层括号\n",
    "#print(Label)\n",
    "num_classes = int(np.max(Label))+1\n",
    "print(Label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e71e6c-b618-4a68-90da-64ab0720edab",
   "metadata": {},
   "source": [
    "## 3) build your own neural network based on fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c77568-a973-444d-95c8-b9fb70190a6f",
   "metadata": {},
   "source": [
    "Design the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7b30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3f6f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FCNNModel(nn.Module):\n",
    "#     def __init__(self, *args):\n",
    "#         super().__init__()\n",
    "#         # code by yourself\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # code by yourself\n",
    "\n",
    "class JYT_model(nn.Module):\n",
    "    def __init__(self, input_layer_size, hidden_layer_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(input_layer_size, hidden_layer_size)\n",
    "        self.out = nn.Linear(hidden_layer_size, num_classes)\n",
    "        self.drop_out = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x));\n",
    "        x = self.drop_out(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0662eb3b-c72d-4331-8c4f-8190805692c0",
   "metadata": {},
   "source": [
    "instantiate your model, set a optimizer and define a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1354717-c8e5-4160-a15a-cba6d2669912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JYT_model(input_layer_size=H*W, hidden_layer_size=int(H*W/2), num_classes=num_classes)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff39ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden.weight Parameter containing:\n",
      "tensor([[ 0.0141,  0.0123, -0.0120,  ..., -0.0120, -0.0017,  0.0006],\n",
      "        [ 0.0074, -0.0161,  0.0079,  ..., -0.0005, -0.0084,  0.0043],\n",
      "        [-0.0207, -0.0051,  0.0059,  ...,  0.0026, -0.0014,  0.0154],\n",
      "        ...,\n",
      "        [-0.0088,  0.0153,  0.0067,  ..., -0.0163, -0.0178, -0.0064],\n",
      "        [-0.0096, -0.0161,  0.0124,  ..., -0.0147, -0.0077, -0.0179],\n",
      "        [ 0.0046,  0.0115, -0.0196,  ...,  0.0178,  0.0019,  0.0058]],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1152, 2304])\n",
      "hidden.bias Parameter containing:\n",
      "tensor([-0.0042, -0.0076, -0.0148,  ...,  0.0054, -0.0088, -0.0036],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1152])\n",
      "out.weight Parameter containing:\n",
      "tensor([[ 0.0276, -0.0282, -0.0089,  ..., -0.0117, -0.0269,  0.0200],\n",
      "        [-0.0033, -0.0037, -0.0251,  ...,  0.0286, -0.0097,  0.0013],\n",
      "        [ 0.0094,  0.0138, -0.0053,  ...,  0.0143, -0.0068, -0.0291],\n",
      "        [ 0.0044,  0.0113,  0.0231,  ...,  0.0050,  0.0109,  0.0044]],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([4, 1152])\n",
      "out.bias Parameter containing:\n",
      "tensor([ 0.0083, -0.0208, -0.0242, -0.0187], device='cuda:0',\n",
      "       requires_grad=True) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter, parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd1f77-bf0f-43be-bbfd-dfc3dfca6d57",
   "metadata": {},
   "source": [
    "## 4) train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57afac-7916-4851-89be-3e6f54c4e34d",
   "metadata": {},
   "source": [
    "Encapsulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "637ac95d-107a-4f69-b570-2d38352d3cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "dataset = utils_data.TensorDataset(torch.Tensor(Image), torch.LongTensor(Label))\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_set, test_set = utils_data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = utils_data.DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
    "test_loader = utils_data.DataLoader(dataset=test_set, batch_size=8, shuffle=True)\n",
    "print('Data is ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea0608-ff4d-4da7-94b1-c1d62061d87b",
   "metadata": {},
   "source": [
    "The following is the training and testing process in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b32aa71-a1cc-4398-8d37-e17acd424534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, testing_acc:0.9375, testing_loss:274.5951232910156\n",
      "epoch:1, testing_acc:0.875, testing_loss:348.9240074157715\n",
      "epoch:2, testing_acc:0.875, testing_loss:414.30700302124023\n",
      "epoch:3, testing_acc:0.875, testing_loss:437.20196533203125\n",
      "epoch:4, testing_acc:0.875, testing_loss:473.1040954589844\n",
      "epoch:5, testing_acc:0.875, testing_loss:474.00511169433594\n",
      "epoch:6, testing_acc:0.875, testing_loss:302.4994201660156\n",
      "epoch:7, testing_acc:0.875, testing_loss:489.2295227050781\n",
      "epoch:8, testing_acc:0.9375, testing_loss:310.87945556640625\n",
      "epoch:9, testing_acc:0.9375, testing_loss:193.82566833496094\n",
      "epoch:10, testing_acc:0.875, testing_loss:236.76541137695312\n",
      "epoch:11, testing_acc:0.875, testing_loss:357.8869171142578\n",
      "epoch:12, testing_acc:0.875, testing_loss:353.21771240234375\n",
      "epoch:13, testing_acc:0.9375, testing_loss:259.9726257324219\n",
      "epoch:14, testing_acc:0.875, testing_loss:362.8655471801758\n",
      "epoch:15, testing_acc:0.875, testing_loss:358.9603385925293\n",
      "epoch:16, testing_acc:0.9375, testing_loss:248.7960205078125\n",
      "epoch:17, testing_acc:0.875, testing_loss:424.08187103271484\n",
      "epoch:18, testing_acc:0.875, testing_loss:644.2685546875\n",
      "epoch:19, testing_acc:0.6875, testing_loss:917.3636322021484\n",
      "epoch:20, testing_acc:0.875, testing_loss:464.4158630371094\n",
      "epoch:21, testing_acc:0.875, testing_loss:323.1313018798828\n",
      "epoch:22, testing_acc:0.875, testing_loss:408.88844299316406\n",
      "epoch:23, testing_acc:0.8125, testing_loss:962.3565063476562\n",
      "epoch:24, testing_acc:0.875, testing_loss:732.0809783935547\n",
      "epoch:25, testing_acc:0.8125, testing_loss:353.8106155395508\n",
      "epoch:26, testing_acc:0.75, testing_loss:838.9004058837891\n",
      "epoch:27, testing_acc:0.8125, testing_loss:382.6556396484375\n",
      "epoch:28, testing_acc:0.8125, testing_loss:696.3047485351562\n",
      "epoch:29, testing_acc:0.8125, testing_loss:510.5596160888672\n",
      "epoch:30, testing_acc:0.875, testing_loss:489.05857849121094\n",
      "epoch:31, testing_acc:0.8125, testing_loss:1175.2623901367188\n",
      "epoch:32, testing_acc:0.8125, testing_loss:430.2858428955078\n",
      "epoch:33, testing_acc:0.875, testing_loss:433.4041442871094\n",
      "epoch:34, testing_acc:0.9375, testing_loss:205.71946716308594\n",
      "epoch:35, testing_acc:0.9375, testing_loss:387.95947265625\n",
      "epoch:36, testing_acc:0.875, testing_loss:318.1574401855469\n",
      "epoch:37, testing_acc:0.875, testing_loss:790.625\n",
      "epoch:38, testing_acc:0.875, testing_loss:709.1257629394531\n",
      "epoch:39, testing_acc:0.875, testing_loss:633.4029541015625\n",
      "epoch:40, testing_acc:0.875, testing_loss:631.69384765625\n",
      "epoch:41, testing_acc:0.875, testing_loss:725.3358764648438\n",
      "epoch:42, testing_acc:0.875, testing_loss:385.5391845703125\n",
      "epoch:43, testing_acc:0.75, testing_loss:841.1736526489258\n",
      "epoch:44, testing_acc:0.875, testing_loss:668.7566070556641\n",
      "epoch:45, testing_acc:0.9375, testing_loss:349.64312744140625\n",
      "epoch:46, testing_acc:0.875, testing_loss:87.39945220947266\n",
      "epoch:47, testing_acc:0.9375, testing_loss:228.39892578125\n",
      "epoch:48, testing_acc:0.9375, testing_loss:417.47833251953125\n",
      "epoch:49, testing_acc:0.9375, testing_loss:208.92236328125\n",
      "epoch:50, testing_acc:0.9375, testing_loss:440.49468994140625\n",
      "epoch:51, testing_acc:0.875, testing_loss:512.0762939453125\n",
      "epoch:52, testing_acc:0.9375, testing_loss:490.8929443359375\n",
      "epoch:53, testing_acc:0.875, testing_loss:738.6303100585938\n",
      "epoch:54, testing_acc:0.875, testing_loss:665.2564086914062\n",
      "epoch:55, testing_acc:0.9375, testing_loss:4.4740142822265625\n",
      "epoch:56, testing_acc:0.8125, testing_loss:543.6487579345703\n",
      "epoch:57, testing_acc:0.9375, testing_loss:394.2196960449219\n",
      "epoch:58, testing_acc:0.9375, testing_loss:238.64218139648438\n",
      "epoch:59, testing_acc:0.75, testing_loss:716.7558746337891\n",
      "epoch:60, testing_acc:0.875, testing_loss:598.7071533203125\n",
      "epoch:61, testing_acc:0.75, testing_loss:1142.9024047851562\n",
      "epoch:62, testing_acc:0.875, testing_loss:803.419921875\n",
      "epoch:63, testing_acc:0.875, testing_loss:381.63468170166016\n",
      "epoch:64, testing_acc:0.9375, testing_loss:113.26986694335938\n",
      "epoch:65, testing_acc:0.9375, testing_loss:11.063026428222656\n",
      "epoch:66, testing_acc:0.9375, testing_loss:91.71456909179688\n",
      "epoch:67, testing_acc:0.875, testing_loss:275.08905029296875\n",
      "epoch:68, testing_acc:0.9375, testing_loss:71.9951171875\n",
      "epoch:69, testing_acc:0.9375, testing_loss:83.88837432861328\n",
      "epoch:70, testing_acc:0.875, testing_loss:354.2921142578125\n",
      "epoch:71, testing_acc:0.875, testing_loss:272.4635009765625\n",
      "epoch:72, testing_acc:0.9375, testing_loss:35.47154235839844\n",
      "epoch:73, testing_acc:0.8125, testing_loss:118.64256286621094\n",
      "epoch:74, testing_acc:0.875, testing_loss:258.5321960449219\n",
      "epoch:75, testing_acc:0.875, testing_loss:396.48094177246094\n",
      "epoch:76, testing_acc:0.875, testing_loss:393.2918395996094\n",
      "epoch:77, testing_acc:0.875, testing_loss:675.9439697265625\n",
      "epoch:78, testing_acc:0.875, testing_loss:424.9607849121094\n",
      "epoch:79, testing_acc:0.8125, testing_loss:324.7052307128906\n",
      "epoch:80, testing_acc:0.875, testing_loss:233.26486206054688\n",
      "epoch:81, testing_acc:0.8125, testing_loss:472.80877685546875\n",
      "epoch:82, testing_acc:0.9375, testing_loss:237.402587890625\n",
      "epoch:83, testing_acc:0.9375, testing_loss:299.7610778808594\n",
      "epoch:84, testing_acc:0.8125, testing_loss:440.4643249511719\n",
      "epoch:85, testing_acc:0.9375, testing_loss:20.659423828125\n",
      "epoch:86, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:87, testing_acc:0.875, testing_loss:342.3189239501953\n",
      "epoch:88, testing_acc:0.8125, testing_loss:377.85501861572266\n",
      "epoch:89, testing_acc:0.875, testing_loss:233.39268493652344\n",
      "epoch:90, testing_acc:0.875, testing_loss:227.29891967773438\n",
      "epoch:91, testing_acc:0.875, testing_loss:172.04052734375\n",
      "epoch:92, testing_acc:0.875, testing_loss:377.7259521484375\n",
      "epoch:93, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:94, testing_acc:0.8125, testing_loss:479.0253143310547\n",
      "epoch:95, testing_acc:0.875, testing_loss:576.5119323730469\n",
      "epoch:96, testing_acc:0.8125, testing_loss:818.6327362060547\n",
      "epoch:97, testing_acc:0.875, testing_loss:407.39076232910156\n",
      "epoch:98, testing_acc:0.8125, testing_loss:1045.6643829345703\n",
      "epoch:99, testing_acc:0.875, testing_loss:414.0628967285156\n",
      "epoch:100, testing_acc:0.9375, testing_loss:472.990966796875\n",
      "epoch:101, testing_acc:0.8125, testing_loss:509.2778625488281\n",
      "epoch:102, testing_acc:0.875, testing_loss:680.8074951171875\n",
      "epoch:103, testing_acc:0.9375, testing_loss:248.5184783935547\n",
      "epoch:104, testing_acc:0.875, testing_loss:133.48638916015625\n",
      "epoch:105, testing_acc:0.9375, testing_loss:29.261260986328125\n",
      "epoch:106, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:107, testing_acc:0.9375, testing_loss:38.57099914550781\n",
      "epoch:108, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:109, testing_acc:0.9375, testing_loss:106.97747802734375\n",
      "epoch:110, testing_acc:0.875, testing_loss:97.13693237304688\n",
      "epoch:111, testing_acc:0.875, testing_loss:122.03275299072266\n",
      "epoch:112, testing_acc:0.9375, testing_loss:68.09345245361328\n",
      "epoch:113, testing_acc:0.9375, testing_loss:80.70556640625\n",
      "epoch:114, testing_acc:0.9375, testing_loss:214.48851013183594\n",
      "epoch:115, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:116, testing_acc:0.9375, testing_loss:104.38163757324219\n",
      "epoch:117, testing_acc:0.9375, testing_loss:194.24227905273438\n",
      "epoch:118, testing_acc:0.875, testing_loss:255.10687255859375\n",
      "epoch:119, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:120, testing_acc:0.9375, testing_loss:148.1495819091797\n",
      "epoch:121, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:122, testing_acc:0.875, testing_loss:363.72509765625\n",
      "epoch:123, testing_acc:0.875, testing_loss:361.98907470703125\n",
      "epoch:124, testing_acc:0.8125, testing_loss:236.67117309570312\n",
      "epoch:125, testing_acc:0.875, testing_loss:517.3116149902344\n",
      "epoch:126, testing_acc:0.8125, testing_loss:945.8052978515625\n",
      "epoch:127, testing_acc:0.8125, testing_loss:675.0242919921875\n",
      "epoch:128, testing_acc:0.9375, testing_loss:81.15074157714844\n",
      "epoch:129, testing_acc:0.9375, testing_loss:485.50555419921875\n",
      "epoch:130, testing_acc:0.875, testing_loss:159.2845687866211\n",
      "epoch:131, testing_acc:0.9375, testing_loss:141.43023681640625\n",
      "epoch:132, testing_acc:0.9375, testing_loss:93.39697265625\n",
      "epoch:133, testing_acc:0.9375, testing_loss:415.7615661621094\n",
      "epoch:134, testing_acc:0.9375, testing_loss:43.35640335083008\n",
      "epoch:135, testing_acc:0.875, testing_loss:149.58648681640625\n",
      "epoch:136, testing_acc:0.875, testing_loss:21.269367218017578\n",
      "epoch:137, testing_acc:0.9375, testing_loss:7.478736877441406\n",
      "epoch:138, testing_acc:0.875, testing_loss:234.7528076171875\n",
      "epoch:139, testing_acc:1.0, testing_loss:0.0\n",
      "epoch:140, testing_acc:0.9375, testing_loss:182.5364532470703\n",
      "epoch:141, testing_acc:0.8125, testing_loss:436.2193298339844\n",
      "epoch:142, testing_acc:0.875, testing_loss:173.19766235351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:143, testing_acc:0.9375, testing_loss:64.23692321777344\n",
      "epoch:144, testing_acc:0.9375, testing_loss:21.604290008544922\n",
      "epoch:145, testing_acc:0.875, testing_loss:473.6740493774414\n",
      "epoch:146, testing_acc:0.9375, testing_loss:768.3223876953125\n",
      "epoch:147, testing_acc:0.9375, testing_loss:525.0159301757812\n",
      "epoch:148, testing_acc:0.9375, testing_loss:635.3720703125\n",
      "epoch:149, testing_acc:0.9375, testing_loss:1090.814453125\n",
      "epoch:150, testing_acc:0.9375, testing_loss:718.93359375\n",
      "epoch:151, testing_acc:0.875, testing_loss:529.3270034790039\n",
      "epoch:152, testing_acc:0.875, testing_loss:468.2075424194336\n",
      "epoch:153, testing_acc:0.9375, testing_loss:376.44915771484375\n",
      "epoch:154, testing_acc:0.875, testing_loss:571.6861114501953\n",
      "epoch:155, testing_acc:0.9375, testing_loss:609.376953125\n",
      "epoch:156, testing_acc:0.875, testing_loss:672.1355743408203\n",
      "epoch:157, testing_acc:0.8125, testing_loss:400.99830627441406\n",
      "epoch:158, testing_acc:0.9375, testing_loss:565.615478515625\n",
      "epoch:159, testing_acc:0.9375, testing_loss:201.62338256835938\n",
      "epoch:160, testing_acc:0.9375, testing_loss:439.6242980957031\n",
      "epoch:161, testing_acc:0.9375, testing_loss:385.642578125\n",
      "epoch:162, testing_acc:0.875, testing_loss:446.0271224975586\n",
      "epoch:163, testing_acc:0.875, testing_loss:315.71185302734375\n",
      "epoch:164, testing_acc:0.875, testing_loss:517.9501037597656\n",
      "epoch:165, testing_acc:0.875, testing_loss:418.7386779785156\n",
      "epoch:166, testing_acc:0.875, testing_loss:676.6853942871094\n",
      "epoch:167, testing_acc:0.875, testing_loss:542.7232131958008\n",
      "epoch:168, testing_acc:0.9375, testing_loss:215.82366943359375\n",
      "epoch:169, testing_acc:0.875, testing_loss:576.4804382324219\n",
      "epoch:170, testing_acc:0.9375, testing_loss:325.1885070800781\n",
      "epoch:171, testing_acc:0.875, testing_loss:462.407958984375\n",
      "epoch:172, testing_acc:0.9375, testing_loss:718.9444580078125\n",
      "epoch:173, testing_acc:0.875, testing_loss:454.1173095703125\n",
      "epoch:174, testing_acc:0.9375, testing_loss:178.05340576171875\n",
      "epoch:175, testing_acc:0.9375, testing_loss:592.08837890625\n",
      "epoch:176, testing_acc:0.875, testing_loss:632.8799438476562\n",
      "epoch:177, testing_acc:0.875, testing_loss:596.6211624145508\n",
      "epoch:178, testing_acc:0.9375, testing_loss:557.5022583007812\n",
      "epoch:179, testing_acc:0.9375, testing_loss:350.27178955078125\n",
      "epoch:180, testing_acc:0.9375, testing_loss:467.2340087890625\n",
      "epoch:181, testing_acc:0.875, testing_loss:377.1162986755371\n",
      "epoch:182, testing_acc:0.875, testing_loss:95.1688003540039\n",
      "epoch:183, testing_acc:0.875, testing_loss:621.8499755859375\n",
      "epoch:184, testing_acc:0.875, testing_loss:594.9872512817383\n",
      "epoch:185, testing_acc:0.9375, testing_loss:302.6357116699219\n",
      "epoch:186, testing_acc:0.9375, testing_loss:672.87353515625\n",
      "epoch:187, testing_acc:0.9375, testing_loss:618.325927734375\n",
      "epoch:188, testing_acc:0.9375, testing_loss:510.34149169921875\n",
      "epoch:189, testing_acc:0.9375, testing_loss:453.48504638671875\n",
      "epoch:190, testing_acc:0.9375, testing_loss:316.8102111816406\n",
      "epoch:191, testing_acc:0.9375, testing_loss:279.87652587890625\n",
      "epoch:192, testing_acc:0.875, testing_loss:450.24761962890625\n",
      "epoch:193, testing_acc:0.875, testing_loss:692.4168701171875\n",
      "epoch:194, testing_acc:0.9375, testing_loss:461.7412109375\n",
      "epoch:195, testing_acc:0.875, testing_loss:311.0823059082031\n",
      "epoch:196, testing_acc:0.9375, testing_loss:293.68267822265625\n",
      "epoch:197, testing_acc:0.8125, testing_loss:702.9235229492188\n",
      "epoch:198, testing_acc:0.9375, testing_loss:397.2644958496094\n",
      "epoch:199, testing_acc:0.875, testing_loss:447.1440734863281\n",
      "epoch:200, testing_acc:0.9375, testing_loss:399.2442626953125\n",
      "epoch:201, testing_acc:0.9375, testing_loss:570.687255859375\n",
      "epoch:202, testing_acc:0.875, testing_loss:408.8714599609375\n",
      "epoch:203, testing_acc:0.875, testing_loss:702.931884765625\n",
      "epoch:204, testing_acc:0.875, testing_loss:459.16688537597656\n",
      "epoch:205, testing_acc:0.875, testing_loss:286.99383544921875\n",
      "epoch:206, testing_acc:0.875, testing_loss:680.8521118164062\n",
      "epoch:207, testing_acc:0.875, testing_loss:354.8734130859375\n",
      "epoch:208, testing_acc:0.875, testing_loss:338.224609375\n",
      "epoch:209, testing_acc:0.9375, testing_loss:542.7828369140625\n",
      "epoch:210, testing_acc:0.875, testing_loss:576.2923355102539\n",
      "epoch:211, testing_acc:0.875, testing_loss:447.2170715332031\n",
      "epoch:212, testing_acc:0.875, testing_loss:757.2781982421875\n",
      "epoch:213, testing_acc:0.9375, testing_loss:539.6607055664062\n",
      "epoch:214, testing_acc:0.9375, testing_loss:501.5135803222656\n",
      "epoch:215, testing_acc:0.875, testing_loss:757.084716796875\n",
      "epoch:216, testing_acc:0.875, testing_loss:871.5794677734375\n",
      "epoch:217, testing_acc:0.875, testing_loss:336.00518798828125\n",
      "epoch:218, testing_acc:0.9375, testing_loss:297.0587463378906\n",
      "epoch:219, testing_acc:0.875, testing_loss:419.23531341552734\n",
      "epoch:220, testing_acc:0.9375, testing_loss:544.8504028320312\n",
      "epoch:221, testing_acc:0.9375, testing_loss:425.26580810546875\n",
      "epoch:222, testing_acc:0.875, testing_loss:402.2742614746094\n",
      "epoch:223, testing_acc:0.875, testing_loss:481.1536331176758\n",
      "epoch:224, testing_acc:0.9375, testing_loss:342.0528869628906\n",
      "epoch:225, testing_acc:0.875, testing_loss:814.934700012207\n",
      "epoch:226, testing_acc:0.875, testing_loss:318.0195617675781\n",
      "epoch:227, testing_acc:0.9375, testing_loss:620.8424682617188\n",
      "epoch:228, testing_acc:0.875, testing_loss:559.4428558349609\n",
      "epoch:229, testing_acc:0.9375, testing_loss:292.3365478515625\n",
      "epoch:230, testing_acc:0.9375, testing_loss:451.2032165527344\n",
      "epoch:231, testing_acc:0.875, testing_loss:576.1484985351562\n",
      "epoch:232, testing_acc:0.9375, testing_loss:157.0899200439453\n",
      "epoch:233, testing_acc:0.875, testing_loss:518.087646484375\n",
      "epoch:234, testing_acc:0.875, testing_loss:520.2289428710938\n",
      "epoch:235, testing_acc:0.875, testing_loss:719.96240234375\n",
      "epoch:236, testing_acc:0.875, testing_loss:956.0355529785156\n",
      "epoch:237, testing_acc:0.875, testing_loss:858.6476745605469\n",
      "epoch:238, testing_acc:0.875, testing_loss:628.7758483886719\n",
      "epoch:239, testing_acc:0.875, testing_loss:377.6925048828125\n",
      "epoch:240, testing_acc:0.875, testing_loss:807.4964904785156\n",
      "epoch:241, testing_acc:0.875, testing_loss:654.4559936523438\n",
      "epoch:242, testing_acc:0.9375, testing_loss:539.108642578125\n",
      "epoch:243, testing_acc:0.9375, testing_loss:651.3765869140625\n",
      "epoch:244, testing_acc:0.875, testing_loss:848.1848754882812\n",
      "epoch:245, testing_acc:0.9375, testing_loss:736.4918823242188\n",
      "epoch:246, testing_acc:0.875, testing_loss:961.1868591308594\n",
      "epoch:247, testing_acc:0.9375, testing_loss:645.7025146484375\n",
      "epoch:248, testing_acc:0.875, testing_loss:928.5523147583008\n",
      "epoch:249, testing_acc:0.9375, testing_loss:1106.8953857421875\n",
      "epoch:250, testing_acc:0.9375, testing_loss:633.7984008789062\n",
      "epoch:251, testing_acc:0.9375, testing_loss:788.8334350585938\n",
      "epoch:252, testing_acc:0.9375, testing_loss:665.7412109375\n",
      "epoch:253, testing_acc:0.9375, testing_loss:762.1546020507812\n",
      "epoch:254, testing_acc:0.875, testing_loss:764.5396575927734\n",
      "epoch:255, testing_acc:0.875, testing_loss:855.1987895965576\n",
      "epoch:256, testing_acc:0.875, testing_loss:820.4337158203125\n",
      "epoch:257, testing_acc:0.875, testing_loss:824.4236354827881\n",
      "epoch:258, testing_acc:0.8125, testing_loss:1037.7013549804688\n",
      "epoch:259, testing_acc:0.9375, testing_loss:450.45867919921875\n",
      "epoch:260, testing_acc:0.8125, testing_loss:1078.2730712890625\n",
      "epoch:261, testing_acc:0.9375, testing_loss:354.69439697265625\n",
      "epoch:262, testing_acc:0.9375, testing_loss:613.4710083007812\n",
      "epoch:263, testing_acc:0.9375, testing_loss:829.9027099609375\n",
      "epoch:264, testing_acc:0.9375, testing_loss:441.04351806640625\n",
      "epoch:265, testing_acc:0.9375, testing_loss:687.3674926757812\n",
      "epoch:266, testing_acc:0.875, testing_loss:747.2022705078125\n",
      "epoch:267, testing_acc:0.875, testing_loss:1096.1650390625\n",
      "epoch:268, testing_acc:0.9375, testing_loss:455.37310791015625\n",
      "epoch:269, testing_acc:0.875, testing_loss:621.6683349609375\n",
      "epoch:270, testing_acc:0.875, testing_loss:730.8489074707031\n",
      "epoch:271, testing_acc:0.9375, testing_loss:858.3577880859375\n",
      "epoch:272, testing_acc:0.875, testing_loss:630.3188934326172\n",
      "epoch:273, testing_acc:0.875, testing_loss:548.9522094726562\n",
      "epoch:274, testing_acc:0.875, testing_loss:767.3473510742188\n",
      "epoch:275, testing_acc:0.875, testing_loss:508.2823486328125\n",
      "epoch:276, testing_acc:0.875, testing_loss:721.9357299804688\n",
      "epoch:277, testing_acc:0.875, testing_loss:663.881103515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:278, testing_acc:0.875, testing_loss:529.0968627929688\n",
      "epoch:279, testing_acc:0.875, testing_loss:508.287109375\n",
      "epoch:280, testing_acc:0.875, testing_loss:838.8486938476562\n",
      "epoch:281, testing_acc:0.875, testing_loss:605.0911102294922\n",
      "epoch:282, testing_acc:0.8125, testing_loss:466.2608947753906\n",
      "epoch:283, testing_acc:0.875, testing_loss:648.2433013916016\n",
      "epoch:284, testing_acc:0.9375, testing_loss:590.8512573242188\n",
      "epoch:285, testing_acc:0.875, testing_loss:430.3374938964844\n",
      "epoch:286, testing_acc:0.875, testing_loss:817.0520629882812\n",
      "epoch:287, testing_acc:0.875, testing_loss:412.95008087158203\n",
      "epoch:288, testing_acc:0.875, testing_loss:809.8721923828125\n",
      "epoch:289, testing_acc:0.875, testing_loss:873.8425140380859\n",
      "epoch:290, testing_acc:0.875, testing_loss:362.2657165527344\n",
      "epoch:291, testing_acc:0.875, testing_loss:260.2716064453125\n",
      "epoch:292, testing_acc:0.875, testing_loss:653.5154724121094\n",
      "epoch:293, testing_acc:0.875, testing_loss:423.339599609375\n",
      "epoch:294, testing_acc:0.875, testing_loss:440.0314636230469\n",
      "epoch:295, testing_acc:0.875, testing_loss:671.3494720458984\n",
      "epoch:296, testing_acc:0.875, testing_loss:776.2986145019531\n",
      "epoch:297, testing_acc:0.875, testing_loss:472.876953125\n",
      "epoch:298, testing_acc:0.875, testing_loss:383.1598663330078\n",
      "epoch:299, testing_acc:0.875, testing_loss:251.9064178466797\n",
      "epoch:300, testing_acc:0.875, testing_loss:452.4797058105469\n",
      "epoch:301, testing_acc:0.8125, testing_loss:644.5848999023438\n",
      "epoch:302, testing_acc:0.8125, testing_loss:864.3121643066406\n",
      "epoch:303, testing_acc:0.875, testing_loss:590.3521728515625\n",
      "epoch:304, testing_acc:0.9375, testing_loss:433.585693359375\n",
      "epoch:305, testing_acc:0.875, testing_loss:843.3544921875\n",
      "epoch:306, testing_acc:0.875, testing_loss:680.0407104492188\n",
      "epoch:307, testing_acc:0.875, testing_loss:802.927116394043\n",
      "epoch:308, testing_acc:0.875, testing_loss:691.7358093261719\n",
      "epoch:309, testing_acc:0.875, testing_loss:643.8489608764648\n",
      "epoch:310, testing_acc:0.875, testing_loss:535.7067108154297\n",
      "epoch:311, testing_acc:0.875, testing_loss:254.5223388671875\n",
      "epoch:312, testing_acc:0.875, testing_loss:527.5185546875\n",
      "epoch:313, testing_acc:0.875, testing_loss:502.9317321777344\n",
      "epoch:314, testing_acc:0.875, testing_loss:598.9641723632812\n",
      "epoch:315, testing_acc:0.875, testing_loss:361.5715637207031\n",
      "epoch:316, testing_acc:0.875, testing_loss:587.8171997070312\n",
      "epoch:317, testing_acc:0.875, testing_loss:554.3690185546875\n",
      "epoch:318, testing_acc:0.875, testing_loss:650.2860717773438\n",
      "epoch:319, testing_acc:0.875, testing_loss:488.1549072265625\n",
      "epoch:320, testing_acc:0.875, testing_loss:874.660888671875\n",
      "epoch:321, testing_acc:0.875, testing_loss:577.239990234375\n",
      "epoch:322, testing_acc:0.875, testing_loss:423.6770477294922\n",
      "epoch:323, testing_acc:0.875, testing_loss:669.2574462890625\n",
      "epoch:324, testing_acc:0.875, testing_loss:525.5797119140625\n",
      "epoch:325, testing_acc:0.875, testing_loss:618.2703247070312\n",
      "epoch:326, testing_acc:0.875, testing_loss:839.01025390625\n",
      "epoch:327, testing_acc:0.875, testing_loss:522.1946334838867\n",
      "epoch:328, testing_acc:0.875, testing_loss:560.4073486328125\n",
      "epoch:329, testing_acc:0.875, testing_loss:398.10089111328125\n",
      "epoch:330, testing_acc:0.875, testing_loss:628.4092407226562\n",
      "epoch:331, testing_acc:0.875, testing_loss:679.5811767578125\n",
      "epoch:332, testing_acc:0.8125, testing_loss:550.8004760742188\n",
      "epoch:333, testing_acc:0.875, testing_loss:504.5381088256836\n",
      "epoch:334, testing_acc:0.875, testing_loss:522.6893920898438\n",
      "epoch:335, testing_acc:0.875, testing_loss:680.9567260742188\n",
      "epoch:336, testing_acc:0.875, testing_loss:558.0039596557617\n",
      "epoch:337, testing_acc:0.8125, testing_loss:724.7409210205078\n",
      "epoch:338, testing_acc:0.875, testing_loss:708.9453125\n",
      "epoch:339, testing_acc:0.875, testing_loss:581.5527954101562\n",
      "epoch:340, testing_acc:0.875, testing_loss:389.51649475097656\n",
      "epoch:341, testing_acc:0.875, testing_loss:725.0159606933594\n",
      "epoch:342, testing_acc:0.875, testing_loss:518.8423118591309\n",
      "epoch:343, testing_acc:0.875, testing_loss:501.031005859375\n",
      "epoch:344, testing_acc:0.875, testing_loss:519.2699737548828\n",
      "epoch:345, testing_acc:0.875, testing_loss:674.2274703979492\n",
      "epoch:346, testing_acc:0.875, testing_loss:921.439697265625\n",
      "epoch:347, testing_acc:0.875, testing_loss:586.5909576416016\n",
      "epoch:348, testing_acc:0.875, testing_loss:274.084716796875\n",
      "epoch:349, testing_acc:0.875, testing_loss:445.85231018066406\n",
      "epoch:350, testing_acc:0.875, testing_loss:736.5943603515625\n",
      "epoch:351, testing_acc:0.9375, testing_loss:425.7220458984375\n",
      "epoch:352, testing_acc:0.875, testing_loss:632.5833740234375\n",
      "epoch:353, testing_acc:0.875, testing_loss:964.3426666259766\n",
      "epoch:354, testing_acc:0.875, testing_loss:824.4138641357422\n",
      "epoch:355, testing_acc:0.8125, testing_loss:615.3904113769531\n",
      "epoch:356, testing_acc:0.875, testing_loss:823.0870056152344\n",
      "epoch:357, testing_acc:0.875, testing_loss:724.4869384765625\n",
      "epoch:358, testing_acc:0.875, testing_loss:412.4099578857422\n",
      "epoch:359, testing_acc:0.875, testing_loss:592.2423095703125\n",
      "epoch:360, testing_acc:0.875, testing_loss:568.3178100585938\n",
      "epoch:361, testing_acc:0.875, testing_loss:436.54776763916016\n",
      "epoch:362, testing_acc:0.875, testing_loss:361.58895111083984\n",
      "epoch:363, testing_acc:0.875, testing_loss:743.0362548828125\n",
      "epoch:364, testing_acc:0.875, testing_loss:718.861572265625\n",
      "epoch:365, testing_acc:0.875, testing_loss:595.3471374511719\n",
      "epoch:366, testing_acc:0.875, testing_loss:590.5363159179688\n",
      "epoch:367, testing_acc:0.875, testing_loss:561.2771301269531\n",
      "epoch:368, testing_acc:0.875, testing_loss:527.2009735107422\n",
      "epoch:369, testing_acc:0.875, testing_loss:1044.40771484375\n",
      "epoch:370, testing_acc:0.875, testing_loss:785.7776107788086\n",
      "epoch:371, testing_acc:0.875, testing_loss:620.592529296875\n",
      "epoch:372, testing_acc:0.875, testing_loss:649.4527435302734\n",
      "epoch:373, testing_acc:0.875, testing_loss:527.9761962890625\n",
      "epoch:374, testing_acc:0.875, testing_loss:782.1914672851562\n",
      "epoch:375, testing_acc:0.875, testing_loss:350.80548095703125\n",
      "epoch:376, testing_acc:0.875, testing_loss:640.1907653808594\n",
      "epoch:377, testing_acc:0.875, testing_loss:702.984130859375\n",
      "epoch:378, testing_acc:0.875, testing_loss:739.2924728393555\n",
      "epoch:379, testing_acc:0.875, testing_loss:503.5198669433594\n",
      "epoch:380, testing_acc:0.875, testing_loss:689.6527099609375\n",
      "epoch:381, testing_acc:0.875, testing_loss:559.1092529296875\n",
      "epoch:382, testing_acc:0.875, testing_loss:737.3853759765625\n",
      "epoch:383, testing_acc:0.875, testing_loss:859.2419586181641\n",
      "epoch:384, testing_acc:0.875, testing_loss:594.8087692260742\n",
      "epoch:385, testing_acc:0.875, testing_loss:537.5008544921875\n",
      "epoch:386, testing_acc:0.875, testing_loss:529.754695892334\n",
      "epoch:387, testing_acc:0.875, testing_loss:269.9997253417969\n",
      "epoch:388, testing_acc:0.875, testing_loss:548.6104278564453\n",
      "epoch:389, testing_acc:0.875, testing_loss:323.827392578125\n",
      "epoch:390, testing_acc:0.875, testing_loss:646.9707641601562\n",
      "epoch:391, testing_acc:0.875, testing_loss:261.4631996154785\n",
      "epoch:392, testing_acc:0.875, testing_loss:618.8579483032227\n",
      "epoch:393, testing_acc:0.875, testing_loss:509.23760986328125\n",
      "epoch:394, testing_acc:0.875, testing_loss:452.138671875\n",
      "epoch:395, testing_acc:0.875, testing_loss:898.5318298339844\n",
      "epoch:396, testing_acc:0.875, testing_loss:654.8946533203125\n",
      "epoch:397, testing_acc:0.875, testing_loss:571.75146484375\n",
      "epoch:398, testing_acc:0.875, testing_loss:727.5224609375\n",
      "epoch:399, testing_acc:0.875, testing_loss:462.34246826171875\n",
      "epoch:400, testing_acc:0.875, testing_loss:414.3829650878906\n",
      "epoch:401, testing_acc:0.875, testing_loss:492.9065628051758\n",
      "epoch:402, testing_acc:0.875, testing_loss:810.1319274902344\n",
      "epoch:403, testing_acc:0.875, testing_loss:710.7803955078125\n",
      "epoch:404, testing_acc:0.875, testing_loss:642.4481201171875\n",
      "epoch:405, testing_acc:0.875, testing_loss:410.6741943359375\n",
      "epoch:406, testing_acc:0.875, testing_loss:554.3216552734375\n",
      "epoch:407, testing_acc:0.875, testing_loss:546.2328796386719\n",
      "epoch:408, testing_acc:0.875, testing_loss:876.363525390625\n",
      "epoch:409, testing_acc:0.875, testing_loss:570.592887878418\n",
      "epoch:410, testing_acc:0.875, testing_loss:703.5397186279297\n",
      "epoch:411, testing_acc:0.875, testing_loss:660.3004150390625\n",
      "epoch:412, testing_acc:0.875, testing_loss:222.70169067382812\n",
      "epoch:413, testing_acc:0.875, testing_loss:443.0093688964844\n",
      "epoch:414, testing_acc:0.875, testing_loss:889.6294555664062\n",
      "epoch:415, testing_acc:0.875, testing_loss:691.6116485595703\n",
      "epoch:416, testing_acc:0.875, testing_loss:419.19549560546875\n",
      "epoch:417, testing_acc:0.875, testing_loss:797.7632446289062\n",
      "epoch:418, testing_acc:0.875, testing_loss:718.197509765625\n",
      "epoch:419, testing_acc:0.875, testing_loss:638.0060424804688\n",
      "epoch:420, testing_acc:0.875, testing_loss:599.289176940918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:421, testing_acc:0.875, testing_loss:649.3555908203125\n",
      "epoch:422, testing_acc:0.875, testing_loss:689.1168518066406\n",
      "epoch:423, testing_acc:0.875, testing_loss:757.2615966796875\n",
      "epoch:424, testing_acc:0.875, testing_loss:320.79249572753906\n",
      "epoch:425, testing_acc:0.875, testing_loss:544.8226013183594\n",
      "epoch:426, testing_acc:0.875, testing_loss:660.5321044921875\n",
      "epoch:427, testing_acc:0.875, testing_loss:589.3108673095703\n",
      "epoch:428, testing_acc:0.875, testing_loss:505.06024169921875\n",
      "epoch:429, testing_acc:0.875, testing_loss:640.0286254882812\n",
      "epoch:430, testing_acc:0.875, testing_loss:596.6590576171875\n",
      "epoch:431, testing_acc:0.875, testing_loss:700.2551727294922\n",
      "epoch:432, testing_acc:0.875, testing_loss:658.4998168945312\n",
      "epoch:433, testing_acc:0.9375, testing_loss:488.3329772949219\n",
      "epoch:434, testing_acc:0.875, testing_loss:977.1179046630859\n",
      "epoch:435, testing_acc:0.875, testing_loss:543.7259368896484\n",
      "epoch:436, testing_acc:0.875, testing_loss:207.3296127319336\n",
      "epoch:437, testing_acc:0.875, testing_loss:653.1133728027344\n",
      "epoch:438, testing_acc:0.875, testing_loss:718.3797302246094\n",
      "epoch:439, testing_acc:0.875, testing_loss:931.3562622070312\n",
      "epoch:440, testing_acc:0.875, testing_loss:613.2559509277344\n",
      "epoch:441, testing_acc:0.875, testing_loss:538.4241943359375\n",
      "epoch:442, testing_acc:0.9375, testing_loss:408.6019287109375\n",
      "epoch:443, testing_acc:0.875, testing_loss:601.27490234375\n",
      "epoch:444, testing_acc:0.875, testing_loss:510.3490295410156\n",
      "epoch:445, testing_acc:0.875, testing_loss:547.5269775390625\n",
      "epoch:446, testing_acc:0.875, testing_loss:648.7366333007812\n",
      "epoch:447, testing_acc:0.875, testing_loss:992.0994873046875\n",
      "epoch:448, testing_acc:0.875, testing_loss:702.9914093017578\n",
      "epoch:449, testing_acc:0.8125, testing_loss:578.9067993164062\n",
      "epoch:450, testing_acc:0.875, testing_loss:363.78804779052734\n",
      "epoch:451, testing_acc:0.875, testing_loss:692.6346435546875\n",
      "epoch:452, testing_acc:0.875, testing_loss:619.7170257568359\n",
      "epoch:453, testing_acc:0.875, testing_loss:457.1105651855469\n",
      "epoch:454, testing_acc:0.875, testing_loss:543.8045043945312\n",
      "epoch:455, testing_acc:0.9375, testing_loss:252.4041748046875\n",
      "epoch:456, testing_acc:0.875, testing_loss:702.0211181640625\n",
      "epoch:457, testing_acc:0.875, testing_loss:771.5756225585938\n",
      "epoch:458, testing_acc:0.875, testing_loss:701.6547241210938\n",
      "epoch:459, testing_acc:0.875, testing_loss:265.1780471801758\n",
      "epoch:460, testing_acc:0.875, testing_loss:502.9432678222656\n",
      "epoch:461, testing_acc:0.875, testing_loss:574.5749816894531\n",
      "epoch:462, testing_acc:0.875, testing_loss:396.64862060546875\n",
      "epoch:463, testing_acc:0.8125, testing_loss:686.3883666992188\n",
      "epoch:464, testing_acc:0.875, testing_loss:459.3000946044922\n",
      "epoch:465, testing_acc:0.875, testing_loss:570.4638061523438\n",
      "epoch:466, testing_acc:0.875, testing_loss:486.57537841796875\n",
      "epoch:467, testing_acc:0.875, testing_loss:642.697265625\n",
      "epoch:468, testing_acc:0.875, testing_loss:316.4648742675781\n",
      "epoch:469, testing_acc:0.875, testing_loss:339.1712646484375\n",
      "epoch:470, testing_acc:0.8125, testing_loss:471.30828857421875\n",
      "epoch:471, testing_acc:0.875, testing_loss:31.71038055419922\n",
      "epoch:472, testing_acc:0.875, testing_loss:530.4388275146484\n",
      "epoch:473, testing_acc:0.875, testing_loss:287.52655029296875\n",
      "epoch:474, testing_acc:0.875, testing_loss:335.8386001586914\n",
      "epoch:475, testing_acc:0.875, testing_loss:360.98004150390625\n",
      "epoch:476, testing_acc:0.9375, testing_loss:104.21971130371094\n",
      "epoch:477, testing_acc:0.9375, testing_loss:324.0635986328125\n",
      "epoch:478, testing_acc:0.875, testing_loss:477.98736572265625\n",
      "epoch:479, testing_acc:0.875, testing_loss:628.2343139648438\n",
      "epoch:480, testing_acc:0.875, testing_loss:1014.5039672851562\n",
      "epoch:481, testing_acc:0.875, testing_loss:575.9420166015625\n",
      "epoch:482, testing_acc:0.875, testing_loss:933.2620544433594\n",
      "epoch:483, testing_acc:0.875, testing_loss:835.0848846435547\n",
      "epoch:484, testing_acc:0.875, testing_loss:846.589111328125\n",
      "epoch:485, testing_acc:0.875, testing_loss:684.8966522216797\n",
      "epoch:486, testing_acc:0.875, testing_loss:1224.61669921875\n",
      "epoch:487, testing_acc:0.875, testing_loss:804.767578125\n",
      "epoch:488, testing_acc:0.875, testing_loss:1004.2908325195312\n",
      "epoch:489, testing_acc:0.875, testing_loss:866.6027221679688\n",
      "epoch:490, testing_acc:0.875, testing_loss:1129.1531524658203\n",
      "epoch:491, testing_acc:0.9375, testing_loss:396.74896240234375\n",
      "epoch:492, testing_acc:0.8125, testing_loss:1222.6981811523438\n",
      "epoch:493, testing_acc:0.875, testing_loss:522.5885620117188\n",
      "epoch:494, testing_acc:0.875, testing_loss:836.2933959960938\n",
      "epoch:495, testing_acc:0.875, testing_loss:756.8982543945312\n",
      "epoch:496, testing_acc:0.875, testing_loss:977.841796875\n",
      "epoch:497, testing_acc:0.875, testing_loss:854.4198608398438\n",
      "epoch:498, testing_acc:0.875, testing_loss:821.1926879882812\n",
      "epoch:499, testing_acc:0.875, testing_loss:1037.9458312988281\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    testing_loss = 0.0\n",
    "    testing_acc = 0.0\n",
    "    for step, (batch_image, batch_label) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        if torch.cuda.is_available():\n",
    "             batch_image, batch_label = batch_image.cuda(), batch_label.cuda()\n",
    "        batch_output = model(batch_image)\n",
    "        batch_loss = loss_func(batch_output, batch_label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        _, train_predicted = torch.max(batch_output.data, 1)\n",
    "        train_acc += (train_predicted == batch_label).sum().item()\n",
    "\n",
    "    train_acc /= train_size\n",
    "    running_loss /= (step+1)\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_label in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                test_data, test_label = test_data.cuda(), test_label.cuda()\n",
    "            test_output = model(test_data)\n",
    "            test_loss = loss_func(test_output, test_label)\n",
    "            \n",
    "            \n",
    "            testing_loss += test_loss.item()\n",
    "            \n",
    "            _, test_pred = torch.max(test_output.data, 1)\n",
    "            testing_acc += (test_pred == test_label).sum().item()\n",
    "        \n",
    "        testing_acc /= test_size\n",
    "        testing_loss /= (step+1)\n",
    "        print(\"epoch:{}, testing_acc:{}, testing_loss:{}\".format(epoch, testing_acc, testing_loss))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43bc6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=499\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=0.875\n"
     ]
    }
   ],
   "source": [
    "    # ----------test----------\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for test_image, test_label in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            test_image, test_label = test_image.cuda(), test_label.cuda()\n",
    "        test_output = model(test_image)\n",
    "        _, predicted = torch.max(test_output.data, 1)\n",
    "        test_acc += (predicted == test_label).sum().item()\n",
    "    test_acc /= test_size\n",
    "\n",
    "    print('epoch={:d}\\ttrain loss={:.6f}\\ttrain accuracy={:.3f}\\ttest accuracy={:.3f}'.format(\n",
    "        epoch, running_loss, train_acc, test_acc))\n",
    "\n",
    "    if test_acc >= best_accuracy:\n",
    "        if not os.path.exists('./trained_models'):\n",
    "            os.makedirs('./trained_models')\n",
    "        torch.save(model.state_dict(), './trained_models/JYT_model.pkl')\n",
    "        best_accuracy = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f51cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2dfcac-3e77-4386-a09f-a6ca8f77350c",
   "metadata": {},
   "source": [
    "# Task 2: Understand body language by gesture recognition with convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b2526-0909-476e-82ca-f688785da04d",
   "metadata": {},
   "source": [
    "## 1. Do literature search on Convolution Neural Network. Learn how to build a convolutional layer in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc76db6-4a78-42d2-b6e7-8835a48df88c",
   "metadata": {},
   "source": [
    "## 2. Referring to the guide in Task 1, build your own network for gesture classification using convolutional layers. Please see the references 4 in the manual to learn how to build convolutional layers in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b39684-c416-4dcc-b380-27d86876dbea",
   "metadata": {},
   "source": [
    "## 3. Analyse and comment on the performance of the model. Make a comparison between the fully connected based and convolutional based models and comment on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4218418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## written by JYT\n",
    "import torch\n",
    "import os\n",
    "import torch.utils.data as utils_data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb8ce6",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c0c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "Image = []\n",
    "path_images = './dataset_processed/images'\n",
    "for mainDir, subDir, files in os.walk(path_images):\n",
    "    for file in files:\n",
    "        \n",
    "        currentPath = os.path.join(mainDir, file)\n",
    "        # print(currentPath)\n",
    "        Image.append(cv2.imread(currentPath)[:, :, 0])\n",
    "Image = np.array(Image)\n",
    "dataset_size, H, W = Image.shape\n",
    "\n",
    "\n",
    "print(Image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2d9d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78,)\n"
     ]
    }
   ],
   "source": [
    "Label = []\n",
    "path_labels = './dataset_processed/labels'\n",
    "for file in os.listdir(path_labels):\n",
    "    Label.append(np.loadtxt(os.path.join(path_labels, file)))\n",
    "    \n",
    "\n",
    "Label = np.array(list(itertools.chain.from_iterable(Label)))\n",
    "\n",
    "num_classes = int(np.max(Label))+1\n",
    "print(Label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c500a97",
   "metadata": {},
   "source": [
    "### generate dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9c4abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "task2_dataset = utils_data.TensorDataset(torch.Tensor(Image), torch.Tensor(Label))\n",
    "split_rate = 0.8\n",
    "train_size = int(dataset_size*split_rate)\n",
    "test_size = dataset_size-train_size\n",
    "train_set, test_set = utils_data.random_split(task2_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = utils_data.DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
    "test_loader = utils_data.DataLoader(dataset=test_set, batch_size=8, shuffle=True)\n",
    "print('finish!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bbe51",
   "metadata": {},
   "source": [
    "### build my nerual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a28351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JYT_model(nn.Module):\n",
    "    def __init__(self, nums_class):\n",
    "        super(JYT_model, self).__init__()\n",
    "        self.conv1= nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1, #padding= (kernel_size-1)/2, to maintain the size after concolutionU\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),#24\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), #12\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3, 1, 1),\n",
    "            nn.ReLU(),                  #32 * 12 *12 \n",
    "        )\n",
    "        self.out = nn.Linear(32*12*12, nums_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #print('1', x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print('2', x.shape)\n",
    "        x = self.conv3(x)\n",
    "        #print('3', x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de770e4",
   "metadata": {},
   "source": [
    "### instantiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee4c8d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = JYT_model(nums_class=num_classes)\n",
    "# for name, parameter in net.named_parameters():\n",
    "#     print(name)\n",
    "#     print(parameter)\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb2362b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6f21b",
   "metadata": {},
   "source": [
    "### train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b25dac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,\t training_loss:68.915, \t traing_acc:0.580645\n",
      "epoch:1,\t training_loss:0.570, \t traing_acc:0.822581\n",
      "epoch:2,\t training_loss:0.396, \t traing_acc:0.870968\n",
      "epoch:3,\t training_loss:0.041, \t traing_acc:0.983871\n",
      "epoch:4,\t training_loss:0.006, \t traing_acc:1.000000\n",
      "epoch:5,\t training_loss:0.001, \t traing_acc:1.000000\n",
      "epoch:6,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:7,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:8,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:9,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:10,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:11,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:12,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:13,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:14,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:15,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:16,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:17,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:18,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:19,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:20,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:21,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:22,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:23,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:24,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:25,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:26,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:27,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:28,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:29,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:30,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:31,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:32,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:33,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:34,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:35,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:36,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:37,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:38,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:39,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:40,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:41,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:42,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:43,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:44,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:45,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:46,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:47,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:48,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:49,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:50,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:51,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:52,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:53,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:54,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:55,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:56,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:57,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:58,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:59,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:60,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:61,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:62,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:63,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:64,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:65,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:66,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:67,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:68,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:69,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:70,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:71,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:72,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:73,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:74,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:75,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:76,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:77,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:78,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:79,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:80,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:81,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:82,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:83,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:84,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:85,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:86,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:87,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:88,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:89,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:90,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:91,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:92,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:93,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:94,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:95,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:96,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:97,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:98,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:99,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:100,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:101,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:102,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:103,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:104,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:105,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:106,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:107,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:108,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:109,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:110,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:111,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:112,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:113,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:114,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:115,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:116,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:117,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:118,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:119,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:120,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:121,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:122,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:123,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:124,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:125,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:126,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:127,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:128,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:129,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:130,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:131,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:132,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:133,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:134,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:135,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:136,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:137,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:138,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:139,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:140,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:141,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:142,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:143,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:144,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:145,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:146,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:147,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:148,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:149,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:150,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:151,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:152,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:153,\t training_loss:0.000, \t traing_acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:154,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:155,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:156,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:157,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:158,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:159,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:160,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:161,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:162,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:163,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:164,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:165,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:166,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:167,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:168,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:169,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:170,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:171,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:172,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:173,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:174,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:175,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:176,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:177,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:178,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:179,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:180,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:181,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:182,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:183,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:184,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:185,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:186,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:187,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:188,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:189,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:190,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:191,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:192,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:193,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:194,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:195,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:196,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:197,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:198,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:199,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:200,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:201,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:202,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:203,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:204,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:205,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:206,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:207,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:208,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:209,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:210,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:211,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:212,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:213,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:214,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:215,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:216,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:217,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:218,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:219,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:220,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:221,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:222,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:223,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:224,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:225,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:226,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:227,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:228,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:229,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:230,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:231,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:232,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:233,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:234,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:235,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:236,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:237,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:238,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:239,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:240,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:241,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:242,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:243,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:244,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:245,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:246,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:247,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:248,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:249,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:250,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:251,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:252,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:253,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:254,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:255,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:256,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:257,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:258,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:259,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:260,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:261,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:262,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:263,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:264,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:265,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:266,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:267,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:268,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:269,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:270,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:271,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:272,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:273,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:274,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:275,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:276,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:277,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:278,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:279,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:280,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:281,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:282,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:283,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:284,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:285,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:286,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:287,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:288,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:289,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:290,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:291,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:292,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:293,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:294,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:295,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:296,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:297,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:298,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:299,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:300,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:301,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:302,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:303,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:304,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:305,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:306,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:307,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:308,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:309,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:310,\t training_loss:0.000, \t traing_acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:311,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:312,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:313,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:314,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:315,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:316,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:317,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:318,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:319,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:320,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:321,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:322,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:323,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:324,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:325,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:326,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:327,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:328,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:329,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:330,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:331,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:332,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:333,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:334,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:335,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:336,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:337,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:338,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:339,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:340,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:341,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:342,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:343,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:344,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:345,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:346,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:347,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:348,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:349,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:350,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:351,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:352,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:353,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:354,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:355,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:356,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:357,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:358,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:359,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:360,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:361,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:362,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:363,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:364,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:365,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:366,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:367,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:368,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:369,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:370,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:371,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:372,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:373,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:374,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:375,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:376,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:377,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:378,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:379,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:380,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:381,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:382,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:383,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:384,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:385,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:386,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:387,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:388,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:389,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:390,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:391,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:392,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:393,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:394,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:395,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:396,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:397,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:398,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:399,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:400,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:401,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:402,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:403,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:404,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:405,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:406,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:407,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:408,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:409,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:410,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:411,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:412,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:413,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:414,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:415,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:416,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:417,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:418,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:419,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:420,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:421,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:422,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:423,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:424,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:425,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:426,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:427,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:428,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:429,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:430,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:431,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:432,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:433,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:434,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:435,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:436,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:437,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:438,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:439,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:440,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:441,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:442,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:443,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:444,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:445,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:446,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:447,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:448,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:449,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:450,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:451,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:452,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:453,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:454,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:455,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:456,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:457,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:458,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:459,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:460,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:461,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:462,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:463,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:464,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:465,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:466,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:467,\t training_loss:0.000, \t traing_acc:1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:468,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:469,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:470,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:471,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:472,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:473,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:474,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:475,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:476,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:477,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:478,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:479,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:480,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:481,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:482,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:483,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:484,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:485,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:486,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:487,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:488,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:489,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:490,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:491,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:492,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:493,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:494,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:495,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:496,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:497,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:498,\t training_loss:0.000, \t traing_acc:1.000000\n",
      "epoch:499,\t training_loss:0.000, \t traing_acc:1.000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    training_loss = 0.0\n",
    "    training_acc = 0.0\n",
    "    for step, (img, label) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        if torch.cuda.is_available():\n",
    "            img, label = img.cuda(), label.cuda()\n",
    "        img = img.view(-1,1,H,W)\n",
    "        #print(img.shape)\n",
    "        output = net(img)\n",
    "        #print(output)\n",
    "        #print(output.shape, label.shape)\n",
    "        label=label.to(torch.long)\n",
    "        batch_loss = loss_func(output, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += batch_loss.item()\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        training_acc +=(pred == label).sum().item()\n",
    "    \n",
    "    training_loss /= (step+1)\n",
    "    training_acc /= train_size\n",
    "    \n",
    "    print('epoch:{},\\t training_loss:{:.3f}, \\t traing_acc:{:.6f}'.format(epoch, \n",
    "                    training_loss, training_acc))\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7182fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=499\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=0.875\n"
     ]
    }
   ],
   "source": [
    "    # ----------test----------\n",
    "    net.eval()\n",
    "    test_acc = 0.0\n",
    "\n",
    "    for test_image, test_label in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            test_image, test_label = test_image.cuda(), test_label.cuda()\n",
    "        test_image = test_image.view(-1, 1, H, W)\n",
    "        test_output = net(test_image)\n",
    "        _, predicted = torch.max(test_output.data, 1)\n",
    "        test_acc += (predicted == test_label).sum().item()\n",
    "    test_acc /= test_size\n",
    "\n",
    "    print('epoch={:d}\\ttrain loss={:.6f}\\ttrain accuracy={:.3f}\\ttest accuracy={:.3f}'.format(\n",
    "        epoch, training_loss, training_acc, test_acc))\n",
    "\n",
    "    if test_acc >= best_accuracy:\n",
    "        if not os.path.exists('./trained_models'):\n",
    "            os.makedirs('./trained_models')\n",
    "        torch.save(net.state_dict(), './trained_models/JYT_mode2.pkl')\n",
    "        best_accuracy = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
